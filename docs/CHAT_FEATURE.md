# ğŸ’¬ FonctionnalitÃ© de Chat Contextuel

## Vue d'ensemble

Chaque modal de dÃ©tail dispose maintenant d'un mini-chat intÃ©grÃ© permettant d'itÃ©rer avec Mistral AI sur l'Ã©lÃ©ment spÃ©cifique de la stratÃ©gie.

## FonctionnalitÃ©s

### ğŸ¤– Chat Contextuel
- Discussion en temps rÃ©el avec Mistral AI
- Contexte automatique basÃ© sur le nÅ“ud sÃ©lectionnÃ©
- RÃ©ponses concises et actionnables (2-3 phrases)
- Historique de conversation maintenu

### ğŸ‘ğŸ‘ SystÃ¨me de Vote
- Pouce en l'air (ğŸ‘) pour les bonnes rÃ©ponses
- Pouce en bas (ğŸ‘) pour les mauvaises rÃ©ponses
- Feedback visuel immÃ©diat
- Permet d'amÃ©liorer les futures interactions

### ğŸ¨ Interface
- Toggle entre "DÃ©tails" et "Discuter"
- Design cohÃ©rent avec le reste de l'application
- Scroll automatique vers les nouveaux messages
- Indicateur de chargement pendant la rÃ©ponse

## Architecture

### Composants

#### `NodeChat.tsx`
Composant de chat rÃ©utilisable avec :
- Gestion de l'Ã©tat des messages
- SystÃ¨me de rating
- Auto-scroll
- Gestion du loading

#### `DetailPanel.tsx`
Modal mise Ã  jour avec :
- Toggle chat/dÃ©tails
- IntÃ©gration du composant NodeChat
- Bouton "Discuter" dans le footer

### API Route

#### `/api/chat-node`
Endpoint dÃ©diÃ© pour le chat contextuel :
- **Input** : `nodeTitle`, `nodeContent`, `userMessage`, `conversationHistory`
- **Output** : `message` (rÃ©ponse de Mistral)
- **ModÃ¨le** : `mistral-small-latest`
- **Max tokens** : 300 (rÃ©ponses concises)

## Utilisation

### Pour l'utilisateur

1. Cliquer sur n'importe quel nÅ“ud de l'arbre
2. Dans la modal, cliquer sur "Discuter"
3. Poser une question ou demander des amÃ©liorations
4. Recevoir une rÃ©ponse de Mistral AI
5. Voter avec ğŸ‘ ou ğŸ‘
6. Continuer la conversation

### Exemples de questions

**Pour un Persona :**
- "Quels sont les besoins spÃ©cifiques de ce persona ?"
- "Comment mieux cibler cette audience ?"
- "Quels canaux de communication privilÃ©gier ?"

**Pour un ProblÃ¨me :**
- "Comment quantifier l'impact de ce problÃ¨me ?"
- "Quelles sont les causes racines ?"
- "Comment valider que c'est un vrai problÃ¨me ?"

**Pour une Feature :**
- "Comment prioriser cette fonctionnalitÃ© ?"
- "Quels sont les risques techniques ?"
- "Comment mesurer le succÃ¨s ?"

## Prompt System

Le systÃ¨me utilise un prompt contextualisÃ© :

```
Tu es un expert en stratÃ©gie business qui aide Ã  affiner et amÃ©liorer des Ã©lÃ©ments de stratÃ©gie.

Contexte actuel :
- Ã‰lÃ©ment : [Titre du nÅ“ud]
- Contenu actuel : [DÃ©tails du nÅ“ud]

Ta mission :
- RÃ©pondre de maniÃ¨re concise et actionnable (2-3 phrases max)
- Proposer des amÃ©liorations concrÃ¨tes
- Poser des questions pertinentes pour affiner la stratÃ©gie
- ÃŠtre constructif et encourageant
```

## DonnÃ©es collectÃ©es

### Ratings
Les votes (ğŸ‘/ğŸ‘) sont stockÃ©s localement dans l'Ã©tat du composant.

**Utilisation future possible :**
- Analyser les rÃ©ponses les mieux notÃ©es
- AmÃ©liorer le prompt system
- Fine-tuner le modÃ¨le
- CrÃ©er une base de connaissances

### Historique
L'historique de conversation est maintenu pendant la session et envoyÃ© Ã  chaque requÃªte pour le contexte.

## Performance

### Optimisations
- RÃ©ponses limitÃ©es Ã  300 tokens
- Pas de streaming (rÃ©ponse complÃ¨te)
- Debouncing sur l'input (via Enter)
- Scroll optimisÃ© avec `useRef`

### CoÃ»ts
- ~100-300 tokens par rÃ©ponse
- ModÃ¨le `mistral-small-latest` (Ã©conomique)
- Pas de stockage cÃ´tÃ© serveur

## AmÃ©liorations futures

### Court terme
- [ ] Sauvegarder l'historique dans localStorage
- [ ] Ajouter des suggestions de questions
- [ ] Permettre de copier les rÃ©ponses
- [ ] Ajouter un bouton "RÃ©gÃ©nÃ©rer"

### Moyen terme
- [ ] Streaming des rÃ©ponses
- [ ] SynthÃ¨se vocale des rÃ©ponses
- [ ] Export de la conversation
- [ ] Partage de conversations

### Long terme
- [ ] Fine-tuning basÃ© sur les votes
- [ ] Multi-agents (diffÃ©rents experts)
- [ ] GÃ©nÃ©ration d'images avec Fal.ai
- [ ] IntÃ©gration avec Qdrant pour RAG

## SÃ©curitÃ©

### Validations
- âœ… VÃ©rification des inputs cÃ´tÃ© serveur
- âœ… Limitation de la longueur des messages
- âœ… Rate limiting (via Netlify)
- âœ… ClÃ© API cÃ´tÃ© serveur uniquement

### DonnÃ©es sensibles
- âŒ Pas de stockage des conversations
- âŒ Pas de donnÃ©es personnelles
- âœ… Contexte limitÃ© au nÅ“ud actuel

## Troubleshooting

### Le chat ne rÃ©pond pas
1. VÃ©rifier la clÃ© API Mistral
2. VÃ©rifier les logs Netlify
3. VÃ©rifier la console navigateur

### RÃ©ponses incohÃ©rentes
1. Le contexte est peut-Ãªtre trop court
2. Augmenter `max_tokens` dans l'API route
3. AmÃ©liorer le prompt system

### Performance lente
1. VÃ©rifier la latence rÃ©seau
2. ConsidÃ©rer le streaming
3. Optimiser le prompt

---

**Version** : 1.0.0  
**Date** : Novembre 2024  
**Statut** : âœ… En production
